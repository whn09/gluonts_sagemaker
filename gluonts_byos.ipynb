{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Training with MXNet and Gluon\n",
    "\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). This tutorial will show how to train and test an MNIST model on SageMaker using MXNet and the Gluon API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "# from sagemaker.mxnet import MXNet\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = '/home/ec2-user/SageMaker/gluonts_sagemaker/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data\n",
    "\n",
    "We use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value `inputs` identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=WORK_DIRECTORY, key_prefix='data/gluonts')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the training function\n",
    "\n",
    "We need to provide a training script that can run on the SageMaker platform. The training scripts are essentially the same as one you would write for local training, except that you need to provide a `train` function. The `train` function will check for the validation accuracy at the end of every epoch and checkpoints the best model so far, along with the optimizer state, in the folder `/opt/ml/checkpoints` if the folder path exists, else it will skip the checkpointing. When SageMaker calls your function, it will pass in arguments that describe the training environment. Check the script below to see how this works.\n",
    "\n",
    "The script here is an adaptation of the [Gluon MNIST example](https://github.com/apache/incubator-mxnet/blob/master/example/gluon/mnist.py) provided by the [Apache MXNet](https://mxnet.incubator.apache.org/) project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !cat 'train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training script on SageMaker\n",
    "\n",
    "The ```MXNet``` class allows us to run our training function on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. In this case we will run our training job on a single c4.xlarge instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_config = {'repo': 'https://github.com/whn09/gluonts_sagemaker.git', 'branch': 'main'}\n",
    "\n",
    "hyperparameters = {'algo-name': 'DeepAR', 'freq': '1D', 'prediction-length': 5, 'context-length': 5*10, 'epochs': 2, 'batch-size': 32, 'num-batches-per-epoch': 50}\n",
    "# hyperparameters = {'algo-name': 'NPTS', 'freq': '1D', 'prediction-length': 5, 'context-length': 5*10, 'epochs': 2, 'batch-size': 32, 'num-batches-per-epoch': 50}\n",
    "# hyperparameters = {'algo-name': 'SeasonalNaive', 'freq': '1D', 'prediction-length': 5, 'context-length': 5*10, 'epochs': 2, 'batch-size': 32, 'num-batches-per-epoch': 50}\n",
    "\n",
    "m = PyTorch('train.py',  # MXNet\n",
    "          source_dir='.',\n",
    "          git_config=git_config,\n",
    "          role=role,\n",
    "          instance_count=1,\n",
    "          instance_type='ml.c5.2xlarge', # 'local', 'ml.c5.2xlarge'\n",
    "#           image_uri='579019700964.dkr.ecr.us-east-1.amazonaws.com/gluonts_sagemaker:latest',  # support R\n",
    "          framework_version='1.9.1',  # '1.8.0'ï¼Œ '1.9.1'\n",
    "          py_version='py38',  # 'py37', 'py38'\n",
    "          hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `MXNet` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.fit({'train': inputs+'/train_1D.json', 'test': inputs+'/test_1D.json'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = m.latest_training_job.name\n",
    "# training_job_name = 'mxnet-training-2022-06-08-11-36-58-728'\n",
    "print(training_job_name)\n",
    "# m = MXNet.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we use the MXNet object to build and deploy an MXNetPredictor object. This creates a SageMaker endpoint that we can use to perform inference. \n",
    "\n",
    "This allows us to perform inference on json encoded multi-dimensional arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf model.tar.gz\n",
    "# !aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz .\n",
    "# !tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf model-gluonts.tar.gz\n",
    "# !rm -rf model/DeepAR\n",
    "# !mv DeepAR model/\n",
    "# !cd model && tar -czvf ../model-gluonts.tar.gz *\n",
    "\n",
    "# !aws s3 cp model-gluonts.tar.gz s3://$bucket/$training_job_name/output/model-gluonts.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')  # 'local', 'ml.m5.xlarge'\n",
    "\n",
    "# # BYOM (optional)\n",
    "# # from sagemaker.mxnet.model import MXNetModel\n",
    "# from sagemaker.pytorch.model import PyTorchModel\n",
    "# model = PyTorchModel(model_data='s3://{}/{}/output/model-gluonts.tar.gz'.format(bucket, training_job_name),  # MXNetModel\n",
    "#                          role=role, \n",
    "#                          entry_point='inference.py',\n",
    "# #                          image_uri=\"579019700964.dkr.ecr.us-east-1.amazonaws.com/gluonts_sagemaker:latest\",  # support R\n",
    "#                          framework_version='1.9.1',  # '1.8.0', '1.9.1'\n",
    "#                          py_version='py38')  # 'py37', 'py38'\n",
    "# predictor = model.deploy(instance_type='ml.m5.xlarge', initial_instance_count=1)  # 'local', 'ml.m5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 /home/ec2-user/SageMaker/gluonts_sagemaker/data/test_1D.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this predictor to classify hand-written digits. Drawing into the image box loads the pixel data into a 'data' variable in this notebook, which we can then pass to the mxnet predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "test_data = {\"start\": \"2020-01-22 00:00:00\", \"target\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 5.0, 7.0, 7.0, 7.0, 11.0, 16.0, 21.0, 22.0, 22.0, 22.0, 24.0, 24.0, 40.0, 40.0, 74.0, 84.0, 94.0, 110.0, 110.0, 120.0, 170.0, 174.0, 237.0], \"id\": \"Afghanistan_\"}\n",
    "test_data['target'] = test_data['target'][:-5]\n",
    "\n",
    "data = {'instances': [test_data]}\n",
    "data['freq'] = '1D'\n",
    "data['target_quantile'] = 0.5\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor runs inference on our input data and returns the predicted digit (as a float value, so we convert to int for display)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = predictor.predict(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transformer = m.transformer(\n",
    "#     instance_count=1,\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     strategy=\"SingleRecord\",\n",
    "#     assemble_with=\"Line\",\n",
    "#     output_path=inputs+'/output',\n",
    "# )\n",
    "\n",
    "# test_s3 = inputs + '/test_1D.json'\n",
    "\n",
    "# transformer.transform(test_s3, split_type=\"Line\", wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
